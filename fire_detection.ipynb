{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zmqXtOT6uIBmILpqx1xdxisMhMwUl07_",
      "authorship_tag": "ABX9TyPAq+Z+ivpgKJXJTZ+gUJlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikdommeti/Fire_detection_Model/blob/main/fire_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karthikdommeti/Fire_detection_Model.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CORp-KIRXRQD",
        "outputId": "994630fe-1c6e-4ea2-dab3-18df4a34570a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Fire_detection_Model' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xgxUqvzQFy_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67d3e13-cac3-442a-bdb6-8abf48d5117d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/firedetect\"\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "Ya2fV6qUWk-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.6, 1.4],\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "nf3bPaB7XDur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Training Data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ow8Lf_XFyF",
        "outputId": "a11a9de6-fb19-4b26-cc8e-9bb307e7e6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0BvkBMuXw8i",
        "outputId": "587bbae6-4c10-4dd2-d24e-464424502a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 199 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model Architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J39c1lz9YMTa",
        "outputId": "f5227ebf-d0ec-4989-a558-89996a3b8be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Gt4rTfyjYUti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Class Weights (in case of imbalance)\n",
        "class_labels = train_data.classes\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(class_labels), y=class_labels)\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "print(\"Class Weights:\", class_weights_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfWJdcdJYZzw",
        "outputId": "9a2c1f65-5b9a-44d5-a851-870938376c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: np.float64(0.6622516556291391), 1: np.float64(2.0408163265306123)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Define early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x89d9TrNYhZr",
        "outputId": "991b61af-0a3e-4b97-b098-7df265b8b0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 4s/step - accuracy: 0.6405 - loss: 0.7139 - val_accuracy: 0.8794 - val_loss: 0.2969\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9155 - loss: 0.1984 - val_accuracy: 0.9246 - val_loss: 0.2223\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9181 - loss: 0.2079 - val_accuracy: 0.9196 - val_loss: 0.1815\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9302 - loss: 0.1657 - val_accuracy: 0.9447 - val_loss: 0.1685\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.9670 - loss: 0.1215 - val_accuracy: 0.9296 - val_loss: 0.1785\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.9523 - loss: 0.1449 - val_accuracy: 0.8894 - val_loss: 0.2390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_data)\n",
        "\n",
        "print(f\"\\n✅ Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "print(f\"🧪 Validation Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Y7N7AbckIjsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM_Ogkj4fujQ",
        "outputId": "b8cb1745-6598-44bf-c0de-e8c5d44cfdd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fire_images': 0, 'non_fire_images': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only one training phase\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(accuracy) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, accuracy, label='Training Accuracy', marker='o')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy', marker='s')\n",
        "plt.title('Training and Validation Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qHBzqzPwIcQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the Model to Google Drive\n",
        "model.save('/content/drive/My Drive/fire_detection_model.h5')\n",
        "print(\"✅ Model saved successfully!\")"
      ],
      "metadata": {
        "id": "nGMkaupuIfqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "import gc\n",
        "\n",
        "def predict_fire(image_path, model):\n",
        "    # Force clear memory before prediction\n",
        "    gc.collect()\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(\"❌ Error: Could not load image. Check the path.\")\n",
        "        return\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_resized = cv2.resize(img_rgb, (128, 128))\n",
        "    img_normalized = img_resized / 255.0\n",
        "    img_input = np.expand_dims(img_normalized, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(img_input, verbose=0)[0][0]\n",
        "\n",
        "\n",
        "\n",
        "    # Decision threshold\n",
        "    if prediction < 0.3:\n",
        "        print(\"🔥 Fire Detected!\")\n",
        "    else:\n",
        "        print(\"✅ No Fire Detected.\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/firedetect/fire_images/fire.115.png\"  # Replace with your image path\n",
        "predict_fire(image_path, model)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJkKwSSlqfVr",
        "outputId": "b1102b94-5646-4504-af9b-824cae0cb8d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Fire Detected!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5qNrVOdGnxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}